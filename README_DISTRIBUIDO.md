# ACO DistribuÃ­do com gRPC ğŸœ

Sistema de **OtimizaÃ§Ã£o por ColÃ´nia de Formigas (ACO)** implementado de forma distribuÃ­da usando **gRPC** com arquitetura **Mestre-Worker**.

## ğŸ“‹ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Mestre ACO     â”‚  â† Coordena algoritmo, mantÃ©m feromÃ´nios
â”‚  (Porta 50051)  â”‚     Distribui trabalho, coleta soluÃ§Ãµes
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    â”‚    â”‚         â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â” â”‚  â”Œâ”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â–¼â”€â”€â”€â”€â”
â”‚Workerâ”‚ â”‚  â”‚Workerâ”‚  â”‚Workerâ”‚
â”‚  1   â”‚ â”‚  â”‚  2   â”‚  â”‚  3   â”‚
â””â”€â”€â”€â”€â”€â”€â”˜ â”‚  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    Executam formigas
    localmente em paralelo
```

### Componentes

1. **Mestre (aco_master.py)**
   - MantÃ©m matriz de feromÃ´nios global
   - Coordena iteraÃ§Ãµes do algoritmo
   - Distribui trabalho para workers
   - Recebe e processa soluÃ§Ãµes
   - Atualiza feromÃ´nios centralizadamente
   - MantÃ©m melhor soluÃ§Ã£o encontrada

2. **Workers (aco_worker.py)**
   - Solicitam trabalho ao mestre
   - Executam formigas localmente
   - Enviam soluÃ§Ãµes de volta ao mestre
   - Podem rodar em mÃºltiplos terminais/mÃ¡quinas

## ğŸš€ Como Executar

### 1. InstalaÃ§Ã£o de DependÃªncias

```bash
pip install -r requirements.txt
```

### 2. Gerar CÃ³digo gRPC

**No Windows (PowerShell ou CMD):**
```bash
generate_proto.bat
```

**No Linux/Mac ou Git Bash:**
```bash
chmod +x generate_proto.sh
./generate_proto.sh
```

**Ou manualmente:**
```bash
python -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. aco_distributed.proto
```

Isso irÃ¡ gerar:
- `aco_distributed_pb2.py`
- `aco_distributed_pb2_grpc.py`

### 3. Executar o Sistema

#### **Terminal 1: Mestre**
```bash
python aco_master.py --port 50051 --iterations 10 --ants 5 --workers 2
```

ParÃ¢metros:
- `--port`: Porta do servidor (padrÃ£o: 50051)
- `--iterations`: NÃºmero de iteraÃ§Ãµes do ACO (padrÃ£o: 10)
- `--ants`: Formigas por worker por iteraÃ§Ã£o (padrÃ£o: 5)
- `--workers`: NÃºmero de workers esperados (padrÃ£o: 2)

#### **Terminal 2: Worker 1**
```bash
python aco_worker.py --id 1 --master localhost:50051
```

#### **Terminal 3: Worker 2**
```bash
python aco_worker.py --id 2 --master localhost:50051
```

#### **Terminal 4: Worker 3 (opcional)**
```bash
python aco_worker.py --id 3 --master localhost:50051
```

ParÃ¢metros:
- `--id`: ID Ãºnico do worker (obrigatÃ³rio)
- `--master`: EndereÃ§o do mestre (padrÃ£o: localhost:50051)

## ğŸ“Š Exemplo de ExecuÃ§Ã£o

### SaÃ­da do Mestre:
```
======================================================================
  MESTRE ACO INICIADO
  Tamanho do grafo: 5 nÃ³s
  IteraÃ§Ãµes totais: 10
  Formigas por worker: 5
  Alpha: 1.0 | Beta: 3.0 | Rho: 0.5 | Q: 10
======================================================================

[Mestre] Aguardando 2 worker(s) para comeÃ§ar...

======================================================================
  ITERAÃ‡ÃƒO 1/10
  Melhor custo global: N/A
======================================================================

[Mestre] Worker 1 solicitou trabalho (IteraÃ§Ã£o 1/10)
[Mestre] Worker 2 solicitou trabalho (IteraÃ§Ã£o 1/10)
[Mestre] Worker 1 enviou soluÃ§Ã£o | IteraÃ§Ã£o: 0 | Custo: 14.00
[Mestre] *** NOVA MELHOR SOLUÃ‡ÃƒO *** | Custo: 14.00 | Caminho: [0, 2, 3, 4, 1]
[Mestre] Worker 2 enviou soluÃ§Ã£o | IteraÃ§Ã£o: 0 | Custo: 16.00
[Mestre] Todos os 2 workers completaram suas tarefas!

[Mestre] Atualizando feromÃ´nios com 2 soluÃ§Ãµes...
[Mestre] FeromÃ´nios atualizados!
```

### SaÃ­da do Worker:
```
============================================================
  WORKER 1 INICIADO
  Conectado ao mestre: localhost:50051
============================================================

[Worker 1] Iniciando execuÃ§Ã£o...

============================================================
  WORKER 1 | ITERAÃ‡ÃƒO 1
  Executando 5 formiga(s)...
============================================================

[Worker 1] Formiga 1/5 | Custo: 16.00 | Caminho: [0, 1, 4, 3, 2]
[Worker 1] Formiga 2/5 | Custo: 14.00 | Caminho: [0, 2, 3, 4, 1]
[Worker 1] Formiga 3/5 | Custo: 15.00 | Caminho: [0, 2, 4, 3, 1]
[Worker 1] Formiga 4/5 | Custo: 14.00 | Caminho: [0, 2, 3, 4, 1]
[Worker 1] Formiga 5/5 | Custo: 16.00 | Caminho: [0, 1, 4, 2, 3]

[Worker 1] Melhor soluÃ§Ã£o local: 14.00
[Worker 1] Enviando ao mestre...
[Worker 1] SoluÃ§Ã£o aceita! Melhor custo global: 14.00
```

## ğŸ”§ Estrutura de Arquivos

```
aco-algorithm/
â”œâ”€â”€ aco.py                          # ACO original (nÃ£o usado na versÃ£o distribuÃ­da)
â”œâ”€â”€ graph.py                        # Classe Graph (nÃ£o usado na versÃ£o distribuÃ­da)
â”œâ”€â”€ main.py                         # Main original (nÃ£o usado na versÃ£o distribuÃ­da)
â”‚
â”œâ”€â”€ aco_distributed.proto           # DefiniÃ§Ã£o do protocolo gRPC
â”œâ”€â”€ aco_master.py                   # Servidor Mestre
â”œâ”€â”€ aco_worker.py                   # Cliente Worker
â”‚
â”œâ”€â”€ generate_proto.bat              # Script Windows para gerar cÃ³digo gRPC
â”œâ”€â”€ generate_proto.sh               # Script Linux/Mac para gerar cÃ³digo gRPC
â”œâ”€â”€ requirements.txt                # DependÃªncias Python
â”‚
â”œâ”€â”€ aco_distributed_pb2.py          # Gerado automaticamente
â”œâ”€â”€ aco_distributed_pb2_grpc.py     # Gerado automaticamente
â”‚
â””â”€â”€ README_DISTRIBUIDO.md           # Este arquivo
```

## ğŸ¯ Fluxo de ExecuÃ§Ã£o

### Para cada iteraÃ§Ã£o:

1. **Workers solicitam trabalho** (`RequestWork`)
   - Enviam ID e timestamp ao mestre
   - Mestre responde com:
     - NÃºmero de formigas a executar
     - Matriz de feromÃ´nios atual
     - Matriz de distÃ¢ncias
     - ParÃ¢metros Î± e Î²

2. **Workers executam formigas localmente**
   - Cada worker executa N formigas
   - Formigas constroem soluÃ§Ãµes baseadas em feromÃ´nios
   - Worker encontra melhor soluÃ§Ã£o local

3. **Workers enviam soluÃ§Ãµes** (`SubmitSolution`)
   - Enviam melhor caminho e custo ao mestre
   - Mestre responde com melhor soluÃ§Ã£o global atual

4. **Mestre atualiza sistema**
   - Aguarda todos os workers enviarem soluÃ§Ãµes
   - Atualiza matriz de feromÃ´nios
   - Registra melhor soluÃ§Ã£o encontrada
   - AvanÃ§a para prÃ³xima iteraÃ§Ã£o

5. **FinalizaÃ§Ã£o**
   - ApÃ³s todas as iteraÃ§Ãµes, mestre sinaliza tÃ©rmino
   - Workers recebem flag `finished=True` e encerram

## ğŸ“¡ Protocolo gRPC

### ServiÃ§os

#### `ACOMasterService` (implementado pelo Mestre)

**RequestWork**
- Request: `WorkRequest { worker_id, timestamp }`
- Response: `WorkAssignment { num_ants, iteration, pheromone_matrix, distance_matrix, finished, alpha, beta }`

**SubmitSolution**
- Request: `Solution { worker_id, path, cost, iteration, timestamp }`
- Response: `SolutionResponse { accepted, current_best_cost, current_best_path, message }`

## âš™ï¸ ParÃ¢metros do ACO

- **Î± (alpha)**: Peso do feromÃ´nio (padrÃ£o: 1.0)
  - Maior valor = maior influÃªncia do feromÃ´nio

- **Î² (beta)**: Peso heurÃ­stico (padrÃ£o: 3.0)
  - Maior valor = maior preferÃªncia por distÃ¢ncias curtas

- **Ï (rho)**: Taxa de evaporaÃ§Ã£o (padrÃ£o: 0.5)
  - Valor entre 0 e 1
  - Maior valor = evaporaÃ§Ã£o mais rÃ¡pida

- **Q**: Quantidade de feromÃ´nio depositado (padrÃ£o: 10)
  - SoluÃ§Ãµes melhores depositam mais feromÃ´nio

## ğŸŒ ExecuÃ§Ã£o em MÃºltiplas MÃ¡quinas

Para executar em computadores diferentes:

1. **No servidor (Mestre):**
   ```bash
   python aco_master.py --port 50051 --iterations 20 --workers 3
   ```

2. **Nos clientes (Workers):**
   ```bash
   # Substitua <IP_DO_MESTRE> pelo IP do servidor
   python aco_worker.py --id 1 --master <IP_DO_MESTRE>:50051
   python aco_worker.py --id 2 --master <IP_DO_MESTRE>:50051
   python aco_worker.py --id 3 --master <IP_DO_MESTRE>:50051
   ```

## ğŸ› Troubleshooting

### Erro: "No module named 'aco_distributed_pb2'"
**SoluÃ§Ã£o:** Execute o script de geraÃ§Ã£o do proto:
```bash
generate_proto.bat  # Windows
# ou
./generate_proto.sh  # Linux/Mac
```

### Erro: "No module named 'grpc'"
**SoluÃ§Ã£o:** Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

### Workers nÃ£o conectam ao mestre
**SoluÃ§Ã£o:** 
1. Verifique se o mestre estÃ¡ rodando
2. Verifique o endereÃ§o IP e porta
3. Verifique firewall/antivÃ­rus

### Mestre fica esperando workers eternamente
**SoluÃ§Ã£o:** 
1. Inicie os workers primeiro
2. Ajuste o parÃ¢metro `--workers` para o nÃºmero correto de workers

## ğŸ“ DiferenÃ§as em RelaÃ§Ã£o Ã  VersÃ£o Original

| Aspecto | VersÃ£o Original | VersÃ£o DistribuÃ­da |
|---------|-----------------|-------------------|
| **ExecuÃ§Ã£o** | Single-threaded | Multi-processo |
| **FeromÃ´nios** | Local | Centralizado no mestre |
| **Formigas** | Sequencial | Paralelo entre workers |
| **ComunicaÃ§Ã£o** | N/A | gRPC |
| **Escalabilidade** | Limitada | MÃºltiplas mÃ¡quinas |

## ğŸ“ ComparaÃ§Ã£o com Sistema de ImpressÃ£o

| Sistema de ImpressÃ£o | ACO DistribuÃ­do |
|---------------------|-----------------|
| ExclusÃ£o mÃºtua entre clientes | **NÃƒO necessÃ¡rio** |
| Ricart-Agrawala | **NÃƒO usado** |
| RelÃ³gios de Lamport | **NÃƒO usado** |
| Servidor "burro" | Mestre "inteligente" |
| Clientes competem | Workers colaboram |

**SimplificaÃ§Ã£o:** O ACO distribuÃ­do Ã© mais simples porque os workers nÃ£o competem - eles apenas executam tarefas independentes e reportam ao mestre!

## ğŸ“Š Resultados Esperados

- **Speedup**: Aproximadamente linear com o nÃºmero de workers
- **Qualidade**: Mesma qualidade da versÃ£o centralizada
- **Overhead**: Pequeno overhead de comunicaÃ§Ã£o gRPC

## ğŸ‘¥ Autores

Sistema desenvolvido como exemplo de sistema distribuÃ­do usando gRPC, baseado no algoritmo ACO clÃ¡ssico.

---

**Divirta-se explorando computaÃ§Ã£o distribuÃ­da com colÃ´nia de formigas! ğŸœğŸš€**

